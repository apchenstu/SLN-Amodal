{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from modal.amodal import Amodal\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import random,pickle\n",
    "import cv2,json,os\n",
    "import numpy as np\n",
    "from skimage.measure import regionprops\n",
    "from pycocotools import mask as maskUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAmodalRegion(ann, id):\n",
    "    region = {}\n",
    "    region['id'] = id #used for gt/dt matching\n",
    "    region['segmentation'] = ann['segmentation']\n",
    "    region['score'] = ann['score']\n",
    "    region['isStuff'] = 0  # default things\n",
    "    if 'foreground_ness' in ann:\n",
    "        region['foreground_ness'] = ann['foreground_ness']\n",
    "    if 'invisibleMask' in ann:\n",
    "        region['invisible_mask'] = ann['invisibleMask']\n",
    "    if 'amodalMask' in ann:\n",
    "        region['amodal_mask'] = ann['amodalMask']\n",
    "    return region\n",
    "\n",
    "def createAmodalAnn(image_id, ann_id):\n",
    "    ann = {}\n",
    "    ann['id'] = ann_id\n",
    "    ann['category_id'] = 1 # fake label\n",
    "    ann['image_id'] = image_id\n",
    "    ann['regions']  =[]\n",
    "    return ann\n",
    "\n",
    "def filterDtFile(resFiles, amodalGtImgIds):\n",
    "    amodalDt = {}\n",
    "    id = 0\n",
    "    ann_id = 0\n",
    "    for i, file in enumerate(resFiles):\n",
    "        print(\"processing json %d in total %d\" %(i+1, len(resFiles)))\n",
    "        anns = json.load(open(file))\n",
    "        for ann in anns:\n",
    "            image_id = ann['image_id']\n",
    "            if image_id in amodalGtImgIds:\n",
    "                id = id + 1\n",
    "                if image_id not in amodalDt:\n",
    "                    amodalDt[image_id] = createAmodalAnn(image_id, ann_id)\n",
    "                    ann_id = ann_id + 1\n",
    "                region = createAmodalRegion(ann, id)\n",
    "                amodalDt[image_id]['regions'].append(region)\n",
    "    res = []\n",
    "    for image_id, ann in amodalDt.items():\n",
    "        res.append(ann)\n",
    "    return res\n",
    "\n",
    "def refine_detections(rois, probs, deltas, window, config):\n",
    "    \"\"\"Refine classified proposals and filter overlaps and return final\n",
    "    detections.\n",
    "\n",
    "    Inputs:\n",
    "        rois: [N, (y1, x1, y2, x2)] in normalized coordinates\n",
    "        probs: [N, num_classes]. Class probabilities.\n",
    "        deltas: [N, num_classes, (dy, dx, log(dh), log(dw))]. Class-specific\n",
    "                bounding box deltas.\n",
    "        window: (y1, x1, y2, x2) in image coordinates. The part of the image\n",
    "            that contains the image excluding the padding.\n",
    "\n",
    "    Returns detections shaped: [N, (y1, x1, y2, x2, class_id, score)]\n",
    "    \"\"\"\n",
    "\n",
    "    # Class IDs per ROI\n",
    "    _, class_ids = torch.max(probs, dim=1)\n",
    "\n",
    "    # Class probability of the top class of each ROI\n",
    "    # Class-specific bounding box deltas\n",
    "    idx = torch.arange(class_ids.size()[0]).long()\n",
    "#     if config.GPU_COUNT:\n",
    "#         idx = idx.cuda()\n",
    "    class_scores = probs[idx, class_ids.data]\n",
    "    deltas_specific = deltas[idx, class_ids.data]\n",
    "\n",
    "#    refined_rois = coordinate_convert(rois,deltas_specific,config,config.GPU_COUNT)\n",
    "\n",
    "    # Clip boxes to image window\n",
    "    refined_rois = clip_to_window(window, refined_rois)\n",
    "\n",
    "    # Round and cast to int since we're deadling with pixels now\n",
    "    refined_rois = torch.round(refined_rois)\n",
    "\n",
    "    # TODO: Filter out boxes with zero area\n",
    "\n",
    "    # Filter out background boxes\n",
    "\n",
    "    keep_bool = class_ids>0\n",
    "    if config.USE_NMS:\n",
    "        # Filter out low confidence boxes\n",
    "        if config.DETECTION_MIN_CONFIDENCE:\n",
    "            keep_bool = keep_bool & (class_scores >= config.DETECTION_MIN_CONFIDENCE)\n",
    "\n",
    "        keep = torch.nonzero(keep_bool)\n",
    "        if len(keep)==0:\n",
    "            return [],[]\n",
    "\n",
    "        keep = keep[:,0]\n",
    "\n",
    "        # Apply per-class NMS\n",
    "        pre_nms_class_ids = class_ids[keep.data]\n",
    "        pre_nms_scores = class_scores[keep.data]\n",
    "        pre_nms_rois = refined_rois[keep.data]\n",
    "\n",
    "        for i, class_id in enumerate(unique1d(pre_nms_class_ids)):\n",
    "            # Pick detections of this class\n",
    "            ixs = torch.nonzero(pre_nms_class_ids == class_id)[:,0]\n",
    "\n",
    "            # Sort\n",
    "            ix_rois = pre_nms_rois[ixs.data]\n",
    "            ix_scores = pre_nms_scores[ixs]\n",
    "            ix_scores, order = ix_scores.sort(descending=True)\n",
    "            ix_rois = ix_rois[order.data,:]\n",
    "\n",
    "            class_keep = nms(torch.cat((ix_rois, ix_scores.unsqueeze(1)), dim=1).data, config.DETECTION_NMS_THRESHOLD)\n",
    "\n",
    "            # Map indicies\n",
    "            class_keep = keep[ixs[order[class_keep].data].data]\n",
    "\n",
    "            if i==0:\n",
    "                nms_keep = class_keep\n",
    "            else:\n",
    "                nms_keep = unique1d(torch.cat((nms_keep, class_keep)))\n",
    "        keep = intersect1d(keep, nms_keep)\n",
    "    else:\n",
    "\n",
    "        keep = torch.nonzero(keep_bool).view((-1))\n",
    "        if keep[-1] > 10:\n",
    "\n",
    "            ix_scores, order  = class_scores[keep.data].sort(descending=True)\n",
    "            keep = keep[order[:3]]\n",
    "\n",
    "\n",
    "\n",
    "    # Keep top detections\n",
    "    roi_count = config.DETECTION_MAX_INSTANCES\n",
    "    print(len(keep.data))\n",
    "    if len(keep.data)>0:\n",
    "        top_ids = class_scores[keep.data].sort(descending=True)[1][:]\n",
    "        keep = keep[top_ids.data]\n",
    "\n",
    "        # Arrange output as [N, (y1, x1, y2, x2, class_id, score)]\n",
    "        # Coordinates are in image domain.\n",
    "        result = torch.cat((refined_rois[keep.data],\n",
    "                            class_ids[keep.data].unsqueeze(1).float(),\n",
    "                            class_scores[keep.data].unsqueeze(1)), dim=1)\n",
    "    else:\n",
    "        return [],[]\n",
    "\n",
    "    return result,refined_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "######################  COCOA dataset  ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_bbox(mask):\n",
    "    props = regionprops(mask)\n",
    "\n",
    "    bbox,maxarea = [],0\n",
    "    for prop in props:\n",
    "        y1,x1,y2,x2 = prop.bbox\n",
    "        areas = (y2-y1)*(x2-x1)\n",
    "        if areas>maxarea:\n",
    "            bbox = prop.bbox\n",
    "    return bbox\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ann_file2 = '../datasets/coco_amodal/annotations/COCO_amodal_val2014.json'\n",
    "amodal = Amodal(ann_file2)\n",
    "amodalGtImgIds = amodal.getImgIds()\n",
    "img_info = amodal.dataset['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/AmodalMask[39]/amodal-props-1-500.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-20415de2d2c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m##########  AmodalMask[39] results #######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mann_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../results/AmodalMask[39]/amodal-props-1-500.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilterDtFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamodalGtImgIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/AmodalMask[39]/amodal-props-1-500.json'"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "##########  AmodalMask[39] results #######\n",
    "ann_file = '../results/AmodalMask[39]/amodal-props-1-500.json'\n",
    "anns = json.load(open(ann_file))\n",
    "dt = filterDtFile([ann_file], amodalGtImgIds)\n",
    "dt = sorted(dt, key=lambda reg : reg['image_id'])\n",
    "\n",
    "startInd = 0 \n",
    "## please modify this value if change amodal annotations\n",
    "## amodal-props-501-1000: 501   \n",
    "## amodal-props-1001-1323:1001\n",
    "\n",
    "targetFolder = '../results/AmodalMask[39]/'  ## path to target folder\n",
    "targetFolder = os.path.abspath(targetFolder)\n",
    "if not os.path.exists(targetFolder):\n",
    "    os.mkdir(targetFolder)\n",
    "\n",
    "\n",
    "for i in range(startInd,len(img_info)):\n",
    "    dt_bboxes = []\n",
    "    for region in dt[i]['regions']:\n",
    "        mask = maskUtils.decode(region['segmentation'])\n",
    "        # TO DO get bounding box\n",
    "        bbox = mask_to_bbox(mask)\n",
    "        dt_bboxes.append(bbox)\n",
    "        \n",
    "    imgIds = dt[i]['image_id']\n",
    "    amodal_bboxes = []\n",
    "    for region in amodal.dataset['annotations'][i]['regions']:\n",
    "        amodal_mask,vis_mask = amodal.getAnnMask2(region,img_info[i]['width'],img_info[i]['height'])\n",
    "        bbox = mask_to_bbox(amodal_mask)\n",
    "        amodal_bboxes.append(bbox)\n",
    "        \n",
    "    \n",
    "    dt_bboxes,amodal_bboxes = np.array(dt_bboxes),np.array(amodal_bboxes)\n",
    "    \n",
    "    if dt_bboxes.shape!=(1000,4):\n",
    "        continue\n",
    "\n",
    "        \n",
    "    ## TO DO\n",
    "    # Input: bboxes 1000 ,amodal_mask object N\n",
    "    # output visualize result \n",
    "    final_index = []\n",
    "    for j in range(amodal_bboxes.shape[0]):\n",
    "        dis = np.sum(np.abs(dt_bboxes-amodal_bboxes[j]),axis=1)\n",
    "        final_index.append(np.argmin(dis))\n",
    "    \n",
    "    img = cv2.imread('../datasets/coco_amodal/val2014/'+img_info[i]['file_name']).astype('float')\n",
    "    for j in final_index[::-1]:\n",
    "        color = np.random.random((1, 3)).tolist()[0]\n",
    "        mask = maskUtils.decode(dt[i]['regions'][j]['segmentation'])\n",
    "        \n",
    "        img = apply_mask(img, mask, color)\n",
    "\n",
    "    cv2.imwrite(os.path.join(targetFolder,img_info[i]['file_name']),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "##############   our results   #########\n",
    "filenames = [item['file_name'] for item in img_info]\n",
    "root = '/home/anpei/our_amodal_result/faillCase/'\n",
    "json_list = os.listdir(root)\n",
    "for item in json_list:\n",
    "    if item.endswith('json'):\n",
    "            \n",
    "        f = open(root+item, \"rb\")\n",
    "        files = pickle.load(f)\n",
    "        \n",
    "        amodal_bboxes = []\n",
    "        i = filenames.index(item[:-5])\n",
    "        for region in amodal.dataset['annotations'][i]['regions']:\n",
    "            amodal_mask,vis_mask = amodal.getAnnMask2(region,img_info[i]['width'],img_info[i]['height'])\n",
    "            bbox = mask_to_bbox(amodal_mask)\n",
    "            amodal_bboxes.append(bbox)\n",
    "            \n",
    "        final_index = []\n",
    "        dt_bboxes = files['rois']\n",
    "        amodal_bboxes = np.array(amodal_bboxes)\n",
    "        for j in range(amodal_bboxes.shape[0]):\n",
    "            dis = np.sum(np.abs(dt_bboxes-amodal_bboxes[j]),axis=1)\n",
    "            final_index.append(np.argmin(dis))\n",
    "        \n",
    "        if not os.path.exists(root+item[:-4]):\n",
    "            os.mkdir(root+item[:-4])\n",
    "        \n",
    "        ind = 0\n",
    "        img = cv2.imread('../datasets/coco_amodal/val2014/'+img_info[i]['file_name']).astype('float')\n",
    "        for j in final_index:\n",
    "            color = np.random.random((1, 3)).tolist()[0]\n",
    "            mask = files['masks'][:,:,j]       \n",
    "            img = apply_mask(img, mask, color)\n",
    "   \n",
    "            img = cv2.rectangle(img,(dt_bboxes[j][1],dt_bboxes[j][0]), (dt_bboxes[j][3],dt_bboxes[j][2]), np.array(color)*255, 2)\n",
    "            name = os.path.join(root+item[:-4],'%02d.jpg' % ind )\n",
    "            cv2.imwrite(name,mask*255)\n",
    "            ind += 1\n",
    "\n",
    "        cv2.imwrite(root+'our_'+img_info[i]['file_name'],img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "##############   AmodalMask[39] results   #########\n",
    "root = '../results/our_amodal_COCOA//'\n",
    "img_info = amodal.dataset['images']\n",
    "final_list = ['1533','3525','4154','8480','9514','9463','6341']\n",
    "dx = 1000\n",
    "for i in range(len(dt)):\n",
    "    i += dx\n",
    "    is_in_list = False\n",
    "    for k in final_list:\n",
    "        is_in_list += img_info[i]['file_name'].endswith(k+'.jpg')\n",
    "    if not is_in_list:\n",
    "        continue    \n",
    "        \n",
    "    dt_bboxes = []\n",
    "    for region in dt[i-dx]['regions']:\n",
    "        mask = maskUtils.decode(region['segmentation'])\n",
    "        # TO DO get bounding box\n",
    "        bbox = mask_to_bbox(mask)\n",
    "        dt_bboxes.append(bbox)\n",
    "        \n",
    "    imgIds = dt[i-dx]['image_id']\n",
    "    amodal_bboxes = []\n",
    "    for region in amodal.dataset['annotations'][i]['regions']:\n",
    "        amodal_mask,vis_mask = amodal.getAnnMask2(region,img_info[i]['width'],img_info[i]['height'])\n",
    "        bbox = mask_to_bbox(amodal_mask)\n",
    "        amodal_bboxes.append(bbox)\n",
    "        \n",
    "    dt_bboxes,amodal_bboxes = np.array(dt_bboxes),np.array(amodal_bboxes)\n",
    "    \n",
    "    if dt_bboxes.shape!=(1000,4):\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(root+img_info[i]['file_name'][:-4]):\n",
    "        os.mkdir(root+img_info[i]['file_name'][:-4])\n",
    "        \n",
    "\n",
    "    final_index = []\n",
    "    for j in range(amodal_bboxes.shape[0]):\n",
    "        dis = np.sum(np.abs(dt_bboxes-amodal_bboxes[j]),axis=1)\n",
    "        final_index.append(np.argmin(dis))\n",
    "    \n",
    "    img = cv2.imread('../datasets/coco_amodal/val2014/'+img_info[i]['file_name']).astype('float')\n",
    "    \n",
    "    ind = 0\n",
    "    for j in final_index[::-1]:\n",
    "        mask = maskUtils.decode(dt[i-dx]['regions'][j]['segmentation'])\n",
    "        name = os.path.join(root+img_info[i]['file_name'][:-4],'%02d_' % ind + img_info[i]['file_name'])\n",
    "        cv2.imwrite(name,mask*255)\n",
    "        ind += 1\n",
    "        \n",
    "    name = os.path.join(root+img_info[i]['file_name'][:-4],img_info[i]['file_name'])\n",
    "    cv2.imwrite(name,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "######################  D2S dataset  ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ann_file2 = '../datasets/D2S/annotations/COCO_amodal_val2014.json'\n",
    "amodal = Amodal(ann_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "3\n",
      "3\n",
      "2\n",
      "8\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "##################### D2S DATASET ##################\n",
    "img_info = amodal.dataset['images']\n",
    "amodal.dataset['annotations']= sorted(amodal.dataset['annotations'], key=lambda ann: ann['image_id']) \n",
    "filenames = [item['file_name'] for item in img_info]\n",
    "final_list = ['8302','4929','6022','8625','8312','4706','4811','8111']\n",
    "root = '../results/our_amodal_D2SA/'\n",
    "json_list = os.listdir(root)\n",
    "for item in json_list:\n",
    "    if item.endswith('json'):\n",
    "        is_in_list = False\n",
    "        amodal_bboxes = []\n",
    "        i = filenames.index(item[:-5])\n",
    "        for k in final_list:\n",
    "            is_in_list += img_info[i]['file_name'].endswith(k+'.jpg')\n",
    "        if not is_in_list:\n",
    "            continue\n",
    "\n",
    "        f = open(root+item, \"rb\")\n",
    "        files = pickle.load(f)\n",
    "        \n",
    "        if not os.path.exists(root+img_info[i]['file_name'][:-4]):\n",
    "            os.mkdir(root+img_info[i]['file_name'][:-4])\n",
    "            \n",
    "        for region in amodal.dataset['annotations'][i]['regions']:\n",
    "            amodal_mask,vis_mask = amodal.getAnnMask2(region,img_info[i]['width'],img_info[i]['height'])\n",
    "            bbox = mask_to_bbox(amodal_mask)\n",
    "            amodal_bboxes.append(bbox)\n",
    "            \n",
    "            name = os.path.join(root+img_info[i]['file_name'][:-4],'gt_%02d_' %(len(amodal_bboxes)-1) + img_info[i]['file_name'])\n",
    "            cv2.imwrite(name,amodal_mask*255)\n",
    "\n",
    "            \n",
    "        final_index = []\n",
    "        dt_bboxes = files['rois']\n",
    "        amodal_bboxes = np.array(amodal_bboxes)\n",
    "        for j in range(amodal_bboxes.shape[0]):\n",
    "            dis = np.sum(np.abs(dt_bboxes-amodal_bboxes[j]),axis=1)\n",
    "            final_index.append(np.argmin(dis))\n",
    "        \n",
    "        masks = []\n",
    "\n",
    "            \n",
    "            \n",
    "        img = cv2.imread('../datasets/D2S/val2014/'+img_info[i]['file_name']).astype('float')\n",
    "        for j in final_index:\n",
    "            mask = files['masks'][:,:,j]\n",
    "            name = os.path.join(root+img_info[i]['file_name'][:-4],'our_%02d_' %j + img_info[i]['file_name'])\n",
    "            \n",
    "            cv2.imwrite(name,mask*255)\n",
    "\n",
    "        name = os.path.join(root+img_info[i]['file_name'][:-4],img_info[i]['file_name'])\n",
    "        cv2.imwrite(name,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#################### generate depth order result ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def IOU(mask_A,mask_B):\n",
    "    return np.sum((mask_A*mask_B)>0)/np.sum((mask_A+mask_B)>0)\n",
    "\n",
    "ann_file2 = '../datasets/coco_amodal/annotations/COCO_amodal_val2014.json'\n",
    "amodal = Amodal(ann_file2)\n",
    "img_info = amodal.dataset['images']\n",
    "filenames = [item['file_name'] for item in img_info]\n",
    "root = '/home/anpei/segementation/pytorch-mask-rcnn-coco-ppm/results/our_vis_only/'\n",
    "save_root = '../datasets/coco_amodal/depth_order/vis_val2014/'\n",
    "json_list = os.listdir(root)\n",
    "for item in json_list:\n",
    "    if item.endswith('json'):\n",
    "        amodal_bboxes = []\n",
    "        i = filenames.index(item[:-5])\n",
    "\n",
    "        f = open(root+item, \"rb\")\n",
    "        files = pickle.load(f)\n",
    "        \n",
    "\n",
    "        amodal_masks = []\n",
    "        for region in amodal.dataset['annotations'][i]['regions']:\n",
    "            amodal_mask,vis_mask = amodal.getAnnMask2(region,img_info[i]['width'],img_info[i]['height'])\n",
    "            bbox = mask_to_bbox(amodal_mask)\n",
    "            amodal_bboxes.append(bbox)\n",
    "            amodal_masks.append(amodal_mask)\n",
    "  \n",
    "            \n",
    "        final_index = []\n",
    "        dt_bboxes = files['rois']\n",
    "        amodal_bboxes = np.array(amodal_bboxes)\n",
    "        for j in range(amodal_bboxes.shape[0]):\n",
    "            dis = np.sum(np.abs(dt_bboxes-amodal_bboxes[j]),axis=1)\n",
    "            final_index.append(np.argmin(dis))\n",
    "        \n",
    "        masks = []\n",
    "        for j in final_index:\n",
    "            masks.append(files['masks'][:,:,j])\n",
    "        \n",
    "\n",
    "        count = 0\n",
    "        for i in range(len(amodal_masks)):\n",
    "            for j in range(i+1,len(amodal_masks)):\n",
    "                iou = IOU(amodal_masks[i],amodal_masks[j])\n",
    "\n",
    "                if iou > 0.4 and final_index[i]!=final_index[j]:\n",
    "                    res = np.stack((masks[i],masks[j]),axis=0)\n",
    "                    name = os.path.join(save_root,item[:-9]+'_%d.depth'%count)\n",
    "                    count += 1\n",
    "                    np.save(name,res)\n",
    "                    \n",
    "                    #name = os.path.join(save_root,item[:-5])\n",
    "                    #cv2.imwrite(name,np.concatenate((masks[i],masks[j]),axis=0)*255)\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-f155f954dfa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamodal_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamodal_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIOU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamodal_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mamodal_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miou\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miou\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-382356357a10>\u001b[0m in \u001b[0;36mIOU\u001b[0;34m(mask_A, mask_B)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mIOU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_A\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_A\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmask_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_info\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2076\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################## generate gt depth order\n",
    "img_info = amodal.dataset['images']\n",
    "save_root = '../datasets/coco_amodal/depth_order/val2014/'\n",
    "for i in range(len(amodal.dataset['annotations'])):#\n",
    "    item = img_info[i]['file_name']\n",
    "    amodal_masks,vis_masks = []\n",
    "    for region in amodal.dataset['annotations'][i]['regions']:\n",
    "        amodal_mask,vis_mask = amodal.getAnnMask2(region,img_info[i]['width'],img_info[i]['height'])\n",
    "        amodal_masks.append(amodal_mask)\n",
    "        vis_masks.append(vis_mask)\n",
    "        \n",
    "    count = 0\n",
    "    for i in range(len(amodal_masks)):\n",
    "        for j in range(i+1,len(amodal_masks)):\n",
    "            iou = IOU(amodal_masks[i],amodal_masks[j])\n",
    "\n",
    "            if iou > 0.5 and iou < 0.9:\n",
    "                res = np.stack((amodal_masks[i],amodal_masks[j]),axis=0)\n",
    "                name = os.path.join(save_root,item[:-4]+'%d_%d.depth'%(i,j))\n",
    "                count += 1\n",
    "                np.save(name,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## R(X,Y) on GT\n",
    "def R_xy(modal_masks_a,amodal_masks_b,vis_masks_a,vis_masks_b):\n",
    "    intersetion = (modal_masks_a*amodal_masks_b)>0\n",
    "    invis_a = modal_masks_a - vis_masks_a\n",
    "    invis_b = amodal_masks_b - vis_masks_b\n",
    "    return np.sum(intersetion*invis_a)<np.sum(intersetion*invis_b)\n",
    "    \n",
    "    \n",
    "count,total = 0,0   \n",
    "img_info = amodal.dataset['images']\n",
    "for i in range(len(amodal.dataset['annotations'])):#\n",
    "    item = img_info[i]['file_name']\n",
    "    amodal_masks,vis_masks = [],[]\n",
    "    for region in amodal.dataset['annotations'][i]['regions']:\n",
    "        amodal_mask,vis_mask = amodal.getAnnMask2(region,img_info[i]['width'],img_info[i]['height'])\n",
    "        if len(amodal_mask) and len(vis_mask):\n",
    "            amodal_masks.append(amodal_mask)\n",
    "            vis_masks.append(vis_mask)\n",
    "        \n",
    "    for i in range(len(amodal_masks)):\n",
    "        for j in range(i+1,len(amodal_masks)):\n",
    "            iou = IOU(amodal_masks[i],amodal_masks[j])\n",
    "\n",
    "            if iou > 0.5:\n",
    "                total += 1\n",
    "                if R_xy(amodal_masks[i],amodal_masks[j],vis_masks[i],vis_masks[j]):\n",
    "                    count += 1\n",
    "                    \n",
    "print(count/len(list_npy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## R(X,Y) on ours\n",
    "def R_xy(modal_masks_a,amodal_masks_b,vis_masks_a,vis_masks_b):\n",
    "    intersetion = (modal_masks_a*amodal_masks_b)>0\n",
    "    invis_a = modal_masks_a - vis_masks_a\n",
    "    invis_b = amodal_masks_b - vis_masks_b\n",
    "    return np.sum(intersetion*invis_a)<np.sum(intersetion*invis_b)\n",
    "    \n",
    "root = '../datasets/coco_amodal/depth_order/val2014/'  \n",
    "list_npy = os.listdir(root)\n",
    "count,total = 0,0   \n",
    "for item in list_npy:\n",
    "    if item.endswith('npy'):\n",
    "        mask = np.load(os.path.join(root,item))\n",
    "        if R_xy(mask[0],mask[1],mask[2],mask[3]):\n",
    "            count += 1\n",
    "            \n",
    "print(count/len(list_npy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = '/home/anpei/segementation/pytorch-mask-rcnn-coco-ppm/datasets/coco_amodal/depth_order/amodal_val2014'\n",
    "dir2 = '/home/anpei/segementation/pytorch-mask-rcnn-coco-ppm/datasets/coco_amodal/depth_order/vis_val2014'\n",
    "save_root = '/home/anpei/segementation/pytorch-classification/datasets/coco_amodal/depth_order/val2014/'\n",
    "npy_list = os.listdir(dir1)\n",
    "for item in npy_list:\n",
    "    if item.endswith('npy'):\n",
    "        mask_1 = np.load(os.path.join(dir1,item))\n",
    "        mask_2 = np.load(os.path.join(dir2,item))\n",
    "        \n",
    "        mask = np.concatenate((mask_1,mask_2),axis=0)\n",
    "        #mask = mask[[0,2,1,3]]\n",
    "        name = os.path.join(save_root,item)\n",
    "        np.save(name,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
